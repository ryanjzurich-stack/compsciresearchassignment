<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>AI in Healthcare — Webography</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <style>
    body { font-family: Arial, Helvetica, sans-serif; margin: 28px; color:#222; }
    h1 { margin-bottom: 4px; }
    .back { margin-bottom: 16px; }
    table { border-collapse: collapse; width:100%; margin-bottom: 18px; }
    th, td { border: 1px solid #cfcfcf; padding: 8px; text-align:left; vertical-align:top; }
    th { background:#f5f5f5; width:160px; }
    .site-url { word-break: break-all; }
    .note { font-size:0.95em; color:#555; margin-top:12px; }
  </style>
</head>
<body>
  <p class="back"><a href="project.html">&larr; Back to project page</a></p>
  <h1>AI in Healthcare</h1>
  <p>Two authoritative and informative sources chosen for this subtopic.</p>

  <!-- Source 1 -->
  <h2>Source 1</h2>
  <table>
    <tr>
      <th>URL</th>
      <td class="site-url"><a href="https://pubmed.ncbi.nlm.nih.gov/39230911/" target="_blank" rel="noopener">https://pubmed.ncbi.nlm.nih.gov/39230911/</a></td>
    </tr>
    <tr>
      <th>Site / Author</th>
      <td>PubMed / Raj M. Ratwani, Karey Sutton, Jessica E. Galarraga (JAMA Viewpoint, 2024)</td>
    </tr>
    <tr>
      <th>Abstract (100–150 words)</th>
      <td>
        This JAMA viewpoint examines the problem of algorithmic bias in healthcare AI and highlights practical steps to address it. The authors review how biased training data and deployment choices can produce unequal outcomes for different demographic groups and outline recommendations—such as more representative datasets, transparency measures, and rigorous clinical evaluation—to reduce harm. They emphasize that adoption of AI in hospitals cannot outpace validation: tools must be tested across diverse populations and monitored continuously. The piece is concise but influential because it connects technical sources of bias to real-world clinical risks and policy solutions, making it a useful primer for researchers, clinicians, and administrators working on trustworthy medical AI.
      </td>
    </tr>
  </table>

  <!-- Source 2 -->
  <h2>Source 2</h2>
  <table>
    <tr>
      <th>URL</th>
      <td class="site-url"><a href="https://jamanetwork.com/journals/jama/fullarticle/2840175" target="_blank" rel="noopener">https://jamanetwork.com/journals/jama/fullarticle/2840175</a></td>
    </tr>
    <tr>
      <th>Site / Author</th>
      <td>JAMA / Derek C. Angus et al., "AI, Health, and Health Care Today and Tomorrow" (2025)</td>
    </tr>
    <tr>
      <th>Abstract (100–150 words)</th>
      <td>
        This broad JAMA article synthesizes contemporary developments in clinical AI and considers how to move from promise to safe, equitable practice. It surveys current clinical applications—such as diagnostic imaging, triage tools, and predictive analytics—and highlights regulatory, methodological, and ethical hurdles. The authors stress the need for multidisciplinary research designs, stronger real-world validation, and regulatory frameworks that require transparency and post-market surveillance. They also argue for stakeholder engagement (patients, clinicians, data scientists) in research design to ensure utility and fairness. The article is valuable because it frames AI implementation as an ecosystem problem rather than purely a technical one.
      </td>
    </tr>
  </table>

  <p class="note">Note: abstracts above are original summaries written for this webography and are not copied from the source texts.</p>
  <p><a href="project.html">&larr; Back to project</a></p>
</body>
</html>
