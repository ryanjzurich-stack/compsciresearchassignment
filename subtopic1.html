<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>AI in Healthcare</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <style>
    body { 
      font-family: Arial, Helvetica, sans-serif; 
      margin: 28px; 
      color: #ffffff;               /* white text */
      background-color: #b30000;    /* red background */
    }
    h1 { margin-bottom: 4px; }
    .back { margin-bottom: 16px; }

    table { border-collapse: collapse; width:100%; margin-bottom: 18px; }
    th, td { 
      border: 1px solid #ffffff;    /* white borders for visibility */
      padding: 8px; 
      text-align:left; 
      vertical-align:top; 
      color: #ffffff;
    }
    th { 
      background:#800000;           /* darker red for contrast */
      width:160px; 
    }

    a { color: #ffffff; text-decoration: underline; }
    .site-url { word-break: break-all; }

    .note { font-size:0.95em; color:#ffffff; margin-top:12px; }
  </style>
</head>
<body>
  <h1>AI in Healthcare</h1>

  <!-- Source 1 -->
  <h2>Source 1</h2>
  <table>
    <tr>
      <th>URL</th>
      <td class="site-url"><a href="https://pubmed.ncbi.nlm.nih.gov/39230911/" target="_blank" rel="noopener">https://pubmed.ncbi.nlm.nih.gov/39230911/</a></td>
    </tr>
    <tr>
      <th>Site / Author</th>
      <td>PubMed / Raj M. Ratwani, Karey Sutton, Jessica E. Galarraga (JAMA Viewpoint, 2024)</td>
    </tr>
    <tr>
      <th>Abstract</th>
      <td>
        This viewpoint examines bias in healthcare AI algorithms and outlines steps to address it. Ratwani goes in-depth and explains how deployment choices have the potential to produce outcomes that are unequal for different demographic groups. On top of this, he outlines recommendations, most notably greater representation in datasets, transparency measures, and thorough clinical evaluations to reduce potential harm from AI. Artificial Intelligence's adoption in hospitals should never, under any circumstances, outpace validation: tools must be tested across diverse populations and continuously monitored. This piece is influential because of its biases regarding clinical risks in the real world, making it a valuable primer for many researchers and administrators of trustworthy medical AI.
      </td>
    </tr>
  </table>

  <!-- Source 2 -->
  <h2>Source 2</h2>
  <table>
    <tr>
      <th>URL</th>
      <td class="site-url"><a href="https://jamanetwork.com/journals/jama/fullarticle/2840175" target="_blank" rel="noopener">https://jamanetwork.com/journals/jama/fullarticle/2840175</a></td>
    </tr>
    <tr>
      <th>Site / Author</th>
      <td>JAMA / Derek C. Angus et al., "AI, Health, and Health Care Today and Tomorrow" (2025)</td>
    </tr>
    <tr>
      <th>Abstract</th>
      <td>
        This article synthesizes developments in clinical AI and considers how to move from potentially safe to entirely safe clinical practices. Within this article, the authors survey current clinical applications. A need is stressed for multidisciplinary research designs, stronger real-world validation, and regulatory frameworks that require complete transparency. An argument is made for stakeholder engagement (data scientists, clinicians, patients) in research design to ensure utility and fairness. Great insight can be found within this article because it implies that AI implementation is much more of a societal issue than purely a technical one.
      </td>
    </tr>
  </table>

  <p><a href="project.html">&larr; Home Page</a></p>
</body>
</html>
